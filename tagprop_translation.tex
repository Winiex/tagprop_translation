\documentclass[a4paper,twocolumn]{ctexart}
\usepackage{ulem}

\title{TagProp: Discriminative Metric Learning in Nearest Neighbor Models for Image Auto-Annotation 译文}
\author{聂伟琳}
\date{\today}


\begin{document}
\maketitle

\begin{abstract}

图像自动标注是计算机视觉领域中一个很重要的开放问题。
针对这个问题，我们提出了一个判别式训练的近邻模型——TapProp。
在这个模型中，被测试的图片的标签通过使用一个带权重的近邻模型来获取标记过的训练图片集合的方式被预测出来。
而邻居之间的权重则基于邻居排行或者邻居与被测试对象之间的距离。
TapProp 通过直接地最大化预测标签在训练集中的对数似然度的方式，让集成度量学习成为了可能。
如此一来，我们可以将一系列针对图片内容不同方面的特征（譬如局部形状描述符，又譬如全局颜色直方图）的相似度的度量方法非常高效地联系起来。
为了增加对于少见的单词的回想，我们同时也引进了一种针对单词的对于带权重的近邻标签预测进行的\sout{反曲调制}（sigmoidal modulation）。
我们调研了该模型不同变种的运行情况，同时也和其他已经存在的相关工作进行了对比。
我们在三个带有挑战性的数据集上展示了实验结果。
并且，在这全部的三个数据集上，TagProp 都和其它当今的杰出工作相比有非常显著的进步。

\end{abstract}

\section{介绍}

图像自动标注是一个很活跃的研究课题\cite{7,15,16,18}。
它的目标是构建一种能够从标注词库中预测出新图片相关关键词的方法。
这些对于关键词的预测可以被用于为图片推荐标签，以及为标签或者标签集推荐图片。
随着用户提供的视觉内容（譬如照片、视频分享网站，以及桌面照片管理应用）正在变得越来越多，这种给图像进行自动标注的方法也变得越来越重要。
这些超大规模的视觉素材集合引发了自动检索和自动标注的需求。
拥有或多或少的结构化标注的图片正变得越来越多，这也使得机器学习的相关技术被应用进来，进而利用它通过评估精确化标签预测模型的方式来平衡这种可能性。

虽然这个问题很困难，但是学术界还是通过对标准的已标注的数据集进行评估的方式取得了一些进展。
在接下来的部分我们将详细介绍那些和我们的成果联系非常紧密的相关工作。
现存的相关工作主要存在两个方面的缺点。
第一点是，模型总是想通过评估来将图片特性和标注之间的生成似然度提高到最大，这样可能对标签预测并不能起到优化作用。
第二点是，许多参量模型并没有足够的能力去精确地获取到图片内容和标注之间极为复杂的依赖关系。
而非参量近邻模型化的方法已经被证明在标签预测上非常成功\cite{5,11,13,17,22,27}。
这主要可以归因于这种类型的模型的高“适配度”：它们可以在更多的数据能够被获取的情况下适配数据中存在的模式。
然而，现成的近邻类型的方法并不能集成定义了近邻从而最大化模型预测效率的度量学习。除去一些展示了针对某些特定计算机视觉问题（譬如图像分类\cite{12}，图像检索\cite{10}，或者是视觉辨识\cite{9}）的度量学习的优点的现存工作外， 在这些近邻类型的方法之中，要么使用的是单一的度量\cite{5,27}，要么使用的是几个度量之间的专有关联\cite{17}。

在这篇论文中，我们展示了 TapProp——它是 Tag Propagation 的缩写——一种新的通过近邻之间标签的存在或缺失的权重联系来预测标签的近邻类模型。
我们所作出的贡献如下所述。
第一，邻居的权重基于邻居的排名或距离来决定，并且自动地通过最大化针对训练图片集的似然度的方式来自动设置。
基于排名的权重中第 k 个邻居将总是获得一个固定的权重，而基于距离的权重则会随着距离的增加发生指数级别的衰减。
我们的标签预测模型从概念上来说是比较简单的，但是依然在使用同样的特征集的情况下获得了比其他一下优秀的方案更好的表现。
第二，和先前的工作不同的是，我们的模型允许对于度量学习的集成。
这使得我们能够通过一些改进（譬如使用图片特征之间的马氏距离，又或者使用几个距离测量的联合）来完善标签预测工作中邻居权重的定义。
第三，TagProp 包含了针对单词的逻辑判别式模型。
这些模型使用单词不变式模型的标签预测和作为输入，而且每个单词的标记仅仅使用了两个参数，从而增加或者减少非常常见或者非常罕见的单词标签呈现的可能性。
这使得被回想起来的单词的数目被显著地提高了。

为了评估我们的模型并且将之和之前的工作进行比较，我们使用了三个数据集—— Corel 5k， IAPR TC12 以及 ESP Game——而评估标准有精确度、回想度、平均准确率以及盈亏平衡点。在图 1 中，我们展示了几个带有相应标注的图像的范例，以及对于这些图片我们的模型所做的标注的预测。在所有的数据集以及评估标准上我们都会展示我们的模型相对于其它早期的工作而言在精确度上的巨大提升。

这篇论文剩下的部分将会是这样的。在接下来的部分我们给出了相关工作的一个概览。然后，在第三部分，我们将展示我们的标签预测模型，以及我们是怎样评估他们的参数的。在第四部分，我们将展示那三个数据集、评估场景以及在我们的试验中所使用的图像特征集合。实验的结构将在第五部分被展示。而在第六部分，我们将展示我们的结论以及我们进一步研究的方向。

\section{相关工作}

在这个部分中我们将会讨论那些和我们的工作最为相关的针对图形自动标注以及关键字检索的模型。我们将这些模型分为了四个主要的类别：基于主题模型的、基于混合模型的，判别式训练的以及近邻模型类的。

第一个类别是类似于狄利克雷分配、概然隐含语义分析或者层级化狄利克雷过程的（例子参见\cite{1,20,25}）基于主题模型的方法。这些方法将图像标注为某些特定主题混合而来的样例，而这些主题中每个主题都是一个关于图片特征和标注文字之间的分布。参数评估上，这些模型评估了每个图片的主题混合和主题的数据分布。最为常见的情况是，这个模型使用了建立在单词之上的多项式分布以及从不同的图片区域获取视觉特征的高斯方法。另外也有一些受机器翻译启发的方法\cite{4}——它们将图像标注的问题看作是从离散的视觉特征中翻译出标注词汇的问题——也可以被理解为给每一个视觉描述符类型提供一个主题的主题模型。

第二个类别的方法使用了混合模型，从而定义了一个图像特征和标注标签之间的联合分布。当需要标注一个新图像的时候，这些模型会通过正规化联合似然读的方式计算在给定视觉特征之后相关标签的条件概率。大多数其他模型会使用训练图片作为组件来定义视觉特征和标签的混合模型\cite{5,11,13}，但有些时候一个关键词会使用固定数目的针对视觉特征的混合组件\cite{2}。每个训练图片会通过一个针对观察值的平滑分布来定义视觉特征和标签的似然度。这些模型可以被看作是基于图片标签的共生关系的\sout{非参数化密度估计}。当基于标注的分布是多项式化的，或者对于每个单词是\sout{分开化伯努力形式}的时候，对于视觉特征会使用高斯化方法。

在上面讨论的两个类型的生成模型都是不够完美的，因为它们最大化了生成数据的似然度，这样并不是对于预测表现而言必要的优化。因此，针对标签预测的判别式模型被提了出来\cite{3,7,10}。这些方法对每一个标签都会习得一个单独的分类器，然后用这些分类器去预测每一个测试图片是否属于该种用相应标签标注了的图片。包括支持向量机、多实例学习、贝页斯方法在内的不同的学习方法都被使用在这种模型之中。值得注意的是，这种模型也阐述了基于多个单词检索图片的问题\cite{7}。

随着越来越多的训练数据可以被获取到，局部学习技术作为一种简单有效的参数化模型的替代方案也正在变得越来越有吸引力。这种技术的案例包括基于在已标记和未标记的图片的相似图之上的标签传播的方法\cite{16,22}，也包括测试图片的邻居的学习判别式模型\cite{27}。一个更简单的特定的近邻标签传输机制最近被提出，它拥有当前最好的运行效果。在这种模型中，近邻们是通过从不同的视觉特征中计算出来的几个距离的平局值来决定的。模型的作者也同时通过习得一个二元分类器进而将有几个标签相似的图片对和没有标签相似的图片对分离开来的方式来把基础距离结合了起来。然而，这种\sout{线性的距离联合}并没有比\sout{平等权重}联合给出更好的结果。

\section{标签相关的预测模型}

我们的目标是预测一个图片的相关标注标签。有了这些相关的预测，我们可以通过给一个给出的图片的标签进行排序的方式来标注图片，或者也可以通过给一个给出的标签的图片进行排序的方式来进行基于标签的关键字检索。我们所提出的方法是基于一个带权重的近邻模型的方式——这主要是受了最近的一些成功的方法的启发\cite{5,11,13,17}——这种方式会将训练图片中的标签图片传播给新的图片。我们的模型是通过判别的方式来进行的学习，而非使用现有的数据\cite{5}，也非用一种特种的方式来使用近邻\cite{17}。我们假设一些图像近似度或图片之间距离的测量方式已经被给出，这样可以从它们的精确定义中抽象出来。

\subsection{带权重近邻标签预测}

为了给图像标注建立模型，我们针对每个关键字使用伯努力模型。这个选择是很自然的，因为关键字和其他的自然文本——在那里通常单词总是有意义的——不一样的是，它总是或有或无的。训练数据中关键字之间的以来关系并没有被模型化，但在我们的模型中被隐式地使用着。

我们使用 \(y_{iw} \in {-1,+1}\) 来表示关键字 \(w\) 对于图片 \(i\) 是存在的还是不存在的，进而我们就可以将图片的标签进行一次编码。图片 \(i\) 的标签存在预测 \(p(y_{iw} = +1)\) 是所有的训练图片权重的集合，通过 \(j\) 来进行索引：
\begin{center}
\({p(y_{iw} = +1) = \displaystyle \sum\limits_{s}\pi_{ij}p(y_{iw} = +1|j)}\)\quad\quad(1)
\({p(y_{iw} = +1|j) = \left\{
\begin{array}{l l}
1 - \epsilon \quad \textrm{for $y_{jw} = + 1$}\\
\epsilon \quad \textrm{otherwise}
\end{array}
\right.}\)\quad(2)
\end{center}
在上面的公式中，\(\pi_{ij}\) 代表了预测图片 \(i\) 的标签时图片 \(j\) 所占的权重。我们规定 \(\pi_{ij} \geq 0\)，并且 \(\displaystyle\sum\limits_{j}\pi_{ij} = 1\)。我们使用 \(\epsilon\) 来防止预测概率为 0，并且在实践中，我们使 \(\epsilon = 10^{-5}\)。为了估计控制权重 \(\pi_{ij}\) 的参数，我们最大化了训练用标注的预测的对数似然度。需要注意的是，训练图片相对于它们本身的权重需要设置为 0（也就是说 \(\pi_{ii} = 0\)），我们的目标是最大化
\begin{center}
\(\zeta = \displaystyle \sum\limits_{i,w}c_{iw}\ln p(y_{iw})\)\quad(3)
\end{center}
在上面的公式中，\(c_{iw}\) 表示考虑了关键字出现与否所带来的不平衡之后的代价。确实，在实践中，标签缺失的情况是比标签存在的情况要多得多的，而且标签的缺失会比标签的存在带来更多的噪音。这是因为大多数标注中的标签是和图片相关的，但是会经常存在标注并没有包含所有相关的标签的情况。如果 \(y_{iw} = +1\)，我们就使 \(c_{iw} = 1/n^+\)，在这里 \(n^+\) 表示所有有意义标签的总数，同样的情况下，我们会使 \(c_{iw} = 1/n^-\) 当 \(y_{iw} = -1\)。

\textbf{基于排名的权重。}\quad 在对 \textit{K} 个近邻使用基于排序的权重时，如果 \(j\) 是 \(i\) 的第 \(k\) 个近邻，我们就使 \(\pi_{ij} = \gamma_{k}\)。数据的对数似然度在参数 \(\gamma_{k}\) 中是凹的，而且可以通过使用一个 EM 算法或者一个映射梯度算法来进行评估。公式 (3) 根据 \(\gamma_{k}\) 推导出来的公式等于：
\begin{center}
\(\frac{\displaystyle \partial\zeta}{\displaystyle \partial\gamma_{k}} = \displaystyle \sum\limits_{i,w}\frac{c_{iw}p(y_{iw}|n_{ik})}{p(y_{iw})}\quad(4)\)
\end{center}
在上面的公式中 \(n_{ik}\) 表示图片 \(i\) 第 \(k\) 个邻居的索引。公式中参数的个数等于邻居的个数 \(K\)。我们将这个变形称作 RK，也就是“rank-based”。

\textbf{基于距离的权重。}\quad 另一种可能就是直接将权重定义为距离的函数，而非排名。这种方法有权重非常自然地依赖于距离的好处，这样的方式在距离在训练的过程中会被调整的情况下是非常重要的。训练图片 \(j\) 对于图片 \(i\) 的权重被如下定义：
\begin{center}
\(\pi_{ij} = \frac{\exp(-d_{\theta}(i,j))}{{\sum_{j^`}\exp{-d_{\theta}(i,j^`)}}^`}\)\quad(5)
\end{center}
在上面的公式中 \(d_{\theta}\) 是我们想要去优化的带有参数 \(\theta\) 的距离度量。需要记住的是，权重 \(\pi_{ij}\) 相对于图片 \(i\) 的距离 \(d_{\theta}\) 是会进行指数级的衰减的。距离 \(d_{\theta}\) 可以选择有一个半有限的矩阵 M 做参数的马氏距离 \(d_{M}\),而且 \(d_{w}(i,j) = w^Td_{ij}\)（这其中 \(d_{ij}\) 是一个在图片 \(i\) 和图片 \(j\) 之间的基本距离组成的矩阵，并且 \(w\) 包含了线性距离联合之间的积极联合影响。而参数的个数等于被联合到一起的基本距离的个数。在这篇论文剩下的篇幅中我们将会聚焦在这个特殊的例子之下。当我们使用单独的距离的时候，我们将会称之为 \(SD\)，\(w\) 是用来控制权重随着距离的衰减度的参数，并且它是这个模型中唯一一个的此类参数。当多个距离被使用时，我们称之为 \(MD\)，也就是“metric learning”。



\newpage

\begin{thebibliography} {99}

\bibitem{1}
K. Barnard, P. Duygulu, D. Forsyth, N. de Freitas, D. Blei,
and M. Jordan. Matching words and pictures. JMLR,
3:1107–1135, 2003.

\bibitem{2}
G. Carneiro, A. Chan, P. Moreno, and N. Vasconcelos. Su-
pervised learning of semantic classes for image annotation
and retrieval. PAMI, 29(3):394–410, 2007.

\bibitem{3}
C. Cusano, G. Ciocca, and R. Schettini. Image annotation
using SVM. In Proceedings Internet imaging (SPIE), volume
5304, 2004.

\bibitem{4}
P. Duygulu, K. Barnard, N. de Freitas, and D. Forsyth. Object
recognition as machine translation: Learning a lexicon for a
ﬁxed image vocabulary. In ECCV, 2002.

\bibitem{5}
S. Feng, R. Manmatha, and V. Lavrenko. Multiple Bernoulli
relevance models for image and video annotation. In CVPR,
2004.

\bibitem{6}
A. Globerson and S. Roweis. Metric learning by collapsing
classes. In NIPS, 2006.

\bibitem{7}
D. Grangier and S. Bengio. A discriminative kernel-based
model to rank images from text queries. PAMI, 30(8):1371–
1384, 2008.

\bibitem{8}
M. Grubinger. Analysis and Evaluation of Visual Informa-
tion Systems Performance. PhD thesis, Victoria University,
Melbourne, Australia, 2007.

\bibitem{9}
M. Guillaumin, J. Verbeek, and C. Schmid. Is that you?
Metric learning approaches for face identiﬁcation. In ICCV,
2009.

\bibitem{10}
T. Hertz, A. Bar-Hillel, and D. Weinshall. Learning distance
functions for image retrieval. In CVPR, 2004.

\bibitem{11}
J. Jeon, V. Lavrenko, and R. Manmatha. Automatic image
annotation and retrieval using cross-media relevance models.
In ACM SIGIR, 2003.

\bibitem{12}
R. Jin, S. Wang, and Z.-H. Zhou. Learning a distance metric
from multi-instance multi-label data. In CVPR, 2009.

\bibitem{13}
V. Lavrenko, R. Manmatha, and J. Jeon. A model for learn-
ing the semantics of pictures. In NIPS, 2003.

\bibitem{14}
S. Lazebnik, C. Schmid, and J. Ponce. Beyond bags of
features: spatial pyramid matching for recognizing natural
scene categories. In CVPR, 2006.

\bibitem{15}
J. Li and J. Wang. Real-time computerized annotation of
pictures. PAMI, 30(6):985–1002, 2008.

\bibitem{16}
J. Liu, M. Li, Q. Liu, H. Lu, and S. Ma. Image annotation via
graph learning. Pattern Recognition, 42(2):218–228, 2009.

\bibitem{17}
A. Makadia, V. Pavlovic, and S. Kumar. A new baseline for
image annotation. In ECCV, 2008.

\bibitem{18}
T. Mei, Y. Wang, X. Hua, S. Gong, and S. Li. Coherent
image annotation by learning semantic distance. In Proceed-
ings of IEEE Conference on Computer Vision and Pattern
Recognition, 2008.

\bibitem{19}
D. Metzler and R. Manmatha. An inference network ap-
proach to image retrieval. In CIVR, 2004.

\bibitem{20}
F. Monay and D. Gatica-Perez. PLSA-based image auto-
annotation: Constraining the latent space. In ACM Multime-
dia, 2004.

\bibitem{21}
A. Oliva and A. Torralba. Modeling the shape of the scene:
a holistic representation of the spatial envelope. IJCV,
42(3):145–175, 2001.

\bibitem{22}
J. Pan, H. Yang, C. Faloutsos, and P. Duygulu. Automatic
multimedia cross-modal correlation discovery. In ACM
SIGKDD, 2004.

\bibitem{23}
J. van de Weijer and C. Schmid. Coloring local feature ex-
traction. In ECCV, 2006.

\bibitem{24}
L. Von Ahn and L. Dabbish. Labeling images with a com-
puter game. In ACM SIGCHI, 2004.

\bibitem{25}
O. Yakhnenko and V. Honavar. Annotating images and im-
age objects using a hierarchical Dirichlet process model.
In Workshop on Multimedia Data Mining ACM SIGKDD,
2008.

\bibitem{26}
A. Yavlinsky, E. Schoﬁeld, and S. R¨uger. Automated image
annotation using global features and robust nonparametric
density estimation. In CIVR, 2005.

\bibitem{27}
H. Zhang, A. Berg, M. Maire, and J. Malik. SVM-KNN:
Discriminative nearest neighbor classiﬁcation for visual cat-
egory recognition. In CVPR, pages 2126–2136, 2006.

\end{thebibliography}

\end{document}
